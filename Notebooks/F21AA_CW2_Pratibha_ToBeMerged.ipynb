{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZL1TFdO7Wxh_"
      },
      "source": [
        "## EDA\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GootH4JXW5GL"
      },
      "source": [
        "#### Frequency of Reviews By Rating\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "3yG_3dddVKog",
        "outputId": "d264fc71-db35-43d8-dc9e-845a2cdca362"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-9-be9f79fed309>:14: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  ax = sns.countplot(x='Score', data=train_data, palette=palette)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "train_data = pd.read_csv(\"train.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# Visualize the distribution of ratings\n",
        "plt.figure(figsize=(5, 5))\n",
        "# Define a pastel palette that increases in hue from 1 to 5\n",
        "palette = sns.color_palette(\"pastel\", n_colors=5)\n",
        "\n",
        "# Plot the count plot with the specified palette\n",
        "ax = sns.countplot(x='Score', data=train_data, palette=palette)\n",
        "plt.title('Frequency of Reviews By Rating')\n",
        "plt.xlabel('Rating')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Get the current plot axes\n",
        "ax = plt.gca()\n",
        "\n",
        "# Loop through each patch (bar in the barplot) to get its position and height and put the text (count)\n",
        "for p in ax.patches:\n",
        "    ax.text(p.get_x() + p.get_width() / 2., p.get_height(), '%d' % int(p.get_height()),\n",
        "            fontsize=8, color='black', ha='center', va='bottom')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kkm570-mZEUJ"
      },
      "source": [
        "#### Exploring the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfwYpSEbZZj4",
        "outputId": "03482d95-4d15-41bb-a95f-26197401b56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Score                                               Text\n",
            "0      5  I received this product early from the seller!...\n",
            "1      5  *****<br />Numi's Collection Assortment Melang...\n",
            "2      5  I was very careful not to overcook this pasta,...\n",
            "3      5  Buying this multi-pack I was misled by the pic...\n",
            "4      5  These bars are so good! I loved them warmed up...\n"
          ]
        }
      ],
      "source": [
        "print(train_data.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyGpbaNjZhAq",
        "outputId": "84c522f4-873d-4a63-e68d-ced3887dccbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 309131 entries, 0 to 309130\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count   Dtype \n",
            "---  ------  --------------   ----- \n",
            " 0   Score   309131 non-null  int64 \n",
            " 1   Text    309131 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 4.7+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "print(train_data.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SoYAzmR5ZlZB",
        "outputId": "10a4f282-736c-4f36-b889-b4d5e84e186e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Score\n",
            "count  309131.000000\n",
            "mean        4.180241\n",
            "std         1.312151\n",
            "min         1.000000\n",
            "25%         4.000000\n",
            "50%         5.000000\n",
            "75%         5.000000\n",
            "max         5.000000\n"
          ]
        }
      ],
      "source": [
        "print(train_data.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxkdUqrqZshf",
        "outputId": "bbca7d10-ce81-426e-957a-30350272f067"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Word Count by Rating:\n",
            "Score\n",
            "1    82.733354\n",
            "2    90.140971\n",
            "3    95.951322\n",
            "4    91.860265\n",
            "5    73.859788\n",
            "Name: word_count, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#Average word count by Rating\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "# Calculate word count for each review(Text)\n",
        "train_data['word_count'] = train_data['Text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Group by 'Rating' and calculate the average word count\n",
        "average_word_count_by_rating = train_data.groupby('Score')['word_count'].mean()\n",
        "\n",
        "\n",
        "print(\"Average Word Count by Rating:\")\n",
        "print(average_word_count_by_rating)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8R_C1h6UZ3X2"
      },
      "source": [
        "\n",
        "### Correlation Between Word Count and Rating Of Reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 825
        },
        "id": "0G2wgOLsZ6Xd",
        "outputId": "20bd0b1a-5ea0-4b4b-9a50-27cab1e4caec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Average Word Count by Rating:\n",
            "   Score  word_count\n",
            "0      1   82.733354\n",
            "1      2   90.140971\n",
            "2      3   95.951322\n",
            "3      4   91.860265\n",
            "4      5   73.859788\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-14-49b21710647a>:21: FutureWarning: \n",
            "\n",
            "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
            "\n",
            "  barplot = sns.barplot(x='Score', y='word_count', data=average_word_count_by_rating, palette=palette)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming train_data is already defined and loaded\n",
        "\n",
        "# Calculate word count for each review(Text)\n",
        "train_data['word_count'] = train_data['Text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Group by Rating and calculate the average word count\n",
        "average_word_count_by_rating = train_data.groupby('Score')['word_count'].mean().reset_index()\n",
        "print(\"Average Word Count by Rating:\")\n",
        "print(average_word_count_by_rating)\n",
        "\n",
        "\n",
        "# Setting up the plot\n",
        "plt.figure(figsize=(10, 6))  # Smaller graph size\n",
        "palette = sns.color_palette(\"pastel\", n_colors=len(average_word_count_by_rating['Score']))\n",
        "\n",
        "# Creating the bar plot\n",
        "barplot = sns.barplot(x='Score', y='word_count', data=average_word_count_by_rating, palette=palette)\n",
        "\n",
        "# Adding the text labels above the bars\n",
        "for p in barplot.patches:\n",
        "    barplot.annotate(format(p.get_height(), '.2f'),\n",
        "                     (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                     ha = 'center', va = 'center',\n",
        "                     size = 10,\n",
        "                     xytext = (0, 5),\n",
        "                     textcoords = 'offset points')\n",
        "\n",
        "# Setting the title and labels\n",
        "plt.title('Average Word Count by Rating', fontsize=14)\n",
        "plt.xlabel('Rating', fontsize=12)\n",
        "plt.ylabel('Average Word Count', fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQgjzMwLgByM"
      },
      "source": [
        "This shows that the average word count for rating 5 is less than the average word count for rating 1 to 4, suggesting that the rating of 5 is more precise averaging approx 74 words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_2nSY4Fe6Qz",
        "outputId": "4974b538-4b4e-4f9d-cf7c-51570f39df1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "          count       mean        std  min   25%   50%    75%    95%     max\n",
            "Score                                                                       \n",
            "1       28521.0  82.733354  76.646718  3.0  37.0  61.0  101.0  214.0  1751.0\n",
            "2       16287.0  90.140971  79.779993  6.0  40.0  67.0  112.0  233.0  1612.0\n",
            "3       23296.0  95.951322  89.100127  7.0  41.0  70.0  121.0  255.0  3432.0\n",
            "4       43876.0  91.860265  87.705394  6.0  37.0  65.0  115.0  249.0  2061.0\n",
            "5      197151.0  73.859788  72.045997  3.0  32.0  52.0   89.0  198.0  2520.0\n"
          ]
        }
      ],
      "source": [
        "# Calculate word count for each review\n",
        "train_data['word_count'] = train_data['Text'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "# Get distribution of word counts by rating\n",
        "distribution_by_rating = train_data.groupby('Score')['word_count'].describe(percentiles=[0.25, 0.5, 0.75, 0.95])\n",
        "\n",
        "# Print the desired statistics\n",
        "print(distribution_by_rating[['count', 'mean', 'std', 'min', '25%', '50%', '75%', '95%', 'max']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9ioGeixg4y0"
      },
      "source": [
        "### Checking Anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvtM009yhCtt"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import nltk # no. to text coversion\n",
        "import inflect\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from bs4 import BeautifulSoup  # for HTML tag removal\n",
        "\n",
        "\n",
        "# Function to check if a review contains only stop words\n",
        "def contains_only_stopwords(text, stopwords):\n",
        "    words = re.findall(r'\\b\\w+\\b', str(text).lower())\n",
        "    return all(word in stopwords for word in words)\n",
        "\n",
        "# Function to check if a review contains only special characters\n",
        "def contains_only_special_chars(text):\n",
        "    return bool(re.match(r'^[\\W_]+$', str(text)))\n",
        "\n",
        "# Function to check if a review contains only digits\n",
        "def contains_only_digits(text):\n",
        "    return bool(re.match(r'^\\d+$', str(text)))\n",
        "\n",
        "# Function to check if a review is empty or filled with white spaces\n",
        "def is_empty_or_space(text):\n",
        "    return str(text).isspace() or not str(text)\n",
        "\n",
        "# Function to check if a review contains HTML tags or URLs\n",
        "def contains_html_or_url(text):\n",
        "    return bool(re.findall(r'<[^>]+>', str(text))) or bool(re.findall(r'http\\S+|www.\\S+', str(text)))\n",
        "\n",
        "def contains_only_html_or_url(text):\n",
        "    # Check if text contains only HTML tags\n",
        "    if bool(re.fullmatch(r'(<[^>]+>)+', str(text))):\n",
        "        return True\n",
        "    # Check if text is just a URL\n",
        "    if bool(re.fullmatch(r'http\\S+|www.\\S+', str(text))):\n",
        "        return True\n",
        "    return False\n",
        "\n",
        "\n",
        "\n",
        "stop_words_set = set(nltk.corpus.stopwords.words('english'))\n",
        "\n",
        "# Count various anomalies in the data\n",
        "missing_data_count = train_data['Text'].isnull().sum()\n",
        "blanks_count = train_data['Text'].apply(is_empty_or_space).sum()\n",
        "only_stop_words_count = train_data['Text'].apply(lambda x: contains_only_stopwords(x, stop_words_set)).sum()\n",
        "only_special_chars_count = train_data['Text'].apply(contains_only_special_chars).sum()\n",
        "only_digits_count = train_data['Text'].apply(contains_only_digits).sum()\n",
        "html_or_url_count = train_data['Text'].apply(contains_html_or_url).sum()\n",
        "only_html_or_url_count = train_data['Text'].apply(contains_only_html_or_url).sum()\n",
        "\n",
        "asterisk_reviews_count = train_data['Text'].apply(lambda x: '*' in str(x)).sum()\n",
        "\n",
        "print(\"Checking Data Anomalies.\")\n",
        "print(\"Reviews with Missing Data/ Nulls:\", missing_data_count)\n",
        "print(\"Reviews with Blanks/ Empty Spaces:\", blanks_count)\n",
        "print(\"Reviews with Only Stop Words:\", only_stop_words_count)\n",
        "print(\"Reviews with Only Special Characters:\", only_special_chars_count)\n",
        "print(\"Reviews with Only Digits:\", only_digits_count)\n",
        "print(\"Reviews with HTML Code/ URL within text:\", html_or_url_count)\n",
        "print(\"Reviews with only HTML Code/ URL:\", only_html_or_url_count)\n",
        "print(\"Reviews with containing '*':\", asterisk_reviews_count)\n",
        "print(\"-----------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTiXcdunyW29",
        "outputId": "83e44a8a-61b0-41b8-a066-96f055c7b593"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oe2ON4l0tHKu"
      },
      "source": [
        "### Trial Preprocessing  No 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxihmdMLjR1G",
        "outputId": "0e6cc052-daad-4dd0-c8ab-78cce9902f0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vs Preprocessed text:\n",
            "                                                Text  \\\n",
            "0  I received this product early from the seller!...   \n",
            "1  *****<br />Numi's Collection Assortment Melang...   \n",
            "2  I was very careful not to overcook this pasta,...   \n",
            "3  Buying this multi-pack I was misled by the pic...   \n",
            "4  These bars are so good! I loved them warmed up...   \n",
            "\n",
            "                                 Preprocessed_Review  \n",
            "0  receiv product earli seller tastey great midda...  \n",
            "1  br numi collect assort melang includesbr herba...  \n",
            "2  care overcook pasta make sure take bite everi ...  \n",
            "3  buy multipack misl pictur whole hazel nut anot...  \n",
            "4  bar good love warm definit think great snack b...  \n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "\n",
        "class TextPreprocessor:\n",
        "    def __init__(self, en_nlp=None):\n",
        "        # Download NLTK resources\n",
        "        nltk.download('punkt', quiet=True)\n",
        "        nltk.download('stopwords', quiet=True)\n",
        "        # Initialize stemmer and stopwords\n",
        "        self.stemmer = PorterStemmer()\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.en_nlp = en_nlp\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return [self.preprocess_text(text) for text in X]\n",
        "\n",
        "    def preprocess_text(self, text):\n",
        "        # Convert to lowercase\n",
        "        text = text.lower()\n",
        "        # Remove special characters\n",
        "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "        # Tokenize\n",
        "        tokens = word_tokenize(text)\n",
        "        # Remove stopwords\n",
        "        tokens = [token for token in tokens if token not in self.stop_words]\n",
        "        # Apply stemming\n",
        "        tokens = [self.stemmer.stem(token) for token in tokens]\n",
        "        # Join tokens back into text\n",
        "        return ' '.join(tokens)\n",
        "\n",
        "# Create preprocessor instance\n",
        "preprocessor = TextPreprocessor()\n",
        "\n",
        "# Apply to dataframe\n",
        "train_data['Preprocessed_Review'] = train_data['Text'].apply(preprocessor.preprocess_text)\n",
        "\n",
        "print(\"Original vs Preprocessed text:\")\n",
        "print(train_data[['Text', 'Preprocessed_Review']].head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYOMkD3Ytco4"
      },
      "source": [
        "### Trial Preprocessing  No 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvgIladmt01c"
      },
      "source": [
        "The following steps have been applied in the pre-processing.<br/>\n",
        "<ul>\n",
        "    <li>Removal of URL and HTML tags</li>\n",
        "    <li>Coversion of text to lower case</li>\n",
        "    <li>Conversion of numbers to text</li>\n",
        "    <li>Handling of special words like A++ and A*</li>\n",
        "    <li>Handling contraction</li>\n",
        "    <li>Stop words removal except negation words</li>\n",
        "    <li>Conversion of emoticons to text</li>\n",
        "    <li>Removal of special characters except + and * </li>\n",
        "    <li>Expanding contractions for specific terms</li>\n",
        "    <li>Excluding reviews which has only stop words</li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iH1O_xytepv",
        "outputId": "ea7cbe5e-982c-47ba-cc9b-01550ce650ef"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 119662 entries, 0 to 119661\n",
            "Data columns (total 3 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   id                   119662 non-null  int64 \n",
            " 1   Original_Review      119662 non-null  object\n",
            " 2   Preprocessed_Review  119662 non-null  object\n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 2.7+ MB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 309131 entries, 0 to 309130\n",
            "Data columns (total 3 columns):\n",
            " #   Column               Non-Null Count   Dtype \n",
            "---  ------               --------------   ----- \n",
            " 0   Original_Review      309131 non-null  object\n",
            " 1   Preprocessed_Review  309131 non-null  object\n",
            " 2   Overall              309131 non-null  int64 \n",
            "dtypes: int64(1), object(2)\n",
            "memory usage: 7.1+ MB\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk # no. to text coversion\n",
        "import inflect\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from bs4 import BeautifulSoup  # for HTML tag removal\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "class TextPreprocessor(BaseEstimator, TransformerMixin):\n",
        "\n",
        "    def __init__(self, remove_urls=True, handle_contractions=True):\n",
        "        self.remove_urls = remove_urls\n",
        "        self.handle_contractions = handle_contractions\n",
        "        self.stop_words = set(stopwords.words('english'))\n",
        "        self.stop_words.difference_update(['no', 'not', \"don't\", 'never', 'none', 'neither', 'nor'])\n",
        "        self.lemmatizer = WordNetLemmatizer()\n",
        "        self.inflect_engine = inflect.engine()\n",
        "        self.emoticon_dict = {\n",
        "            ':)': 'smile',\n",
        "            ':(': 'sad',\n",
        "            ':D': 'happy',\n",
        "            ':d': 'happy',\n",
        "            ':P': 'playful',\n",
        "            ':/': 'confused',\n",
        "            ':|': 'neutral',\n",
        "            ';)': 'wink',\n",
        "            ':*': 'kiss',\n",
        "            '<3': 'heart',\n",
        "            ':O': 'surprised',\n",
        "            ':@': 'angry',\n",
        "            ':S': 'unsure',\n",
        "            ':*(': 'crying',\n",
        "            'XD': 'laughing',\n",
        "            ':>': 'skeptical',\n",
        "            ':3': 'cute',\n",
        "            ':v': 'pacman',\n",
        "            '>:(': 'angry',\n",
        "            ':v': 'happy',\n",
        "            ':poop:': 'poop',\n",
        "            ':rofl:': 'laughing',\n",
        "        }\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        preprocessed_texts = [self.preprocess_text_nltk(text) for text in X]\n",
        "        return preprocessed_texts\n",
        "\n",
        "    def preprocess_text_nltk(self, text):\n",
        "        if not isinstance(text, str) or text.strip() == '':\n",
        "            return ''\n",
        "\n",
        "        # URL and HTML Tag removal\n",
        "        if self.remove_urls:\n",
        "            text = re.sub(r'http\\S+|www.\\S+', '', text)\n",
        "        text = BeautifulSoup(text, \"html.parser\").get_text()\n",
        "\n",
        "\n",
        "        # Convert numbers before further processing\n",
        "        text = self.convert_numbers(text)\n",
        "\n",
        "\n",
        "        # Normalize spaces around '+' and replace specific patterns/ handing special text within train data\n",
        "        #text = re.sub(r'\\s*\\+\\s*', '+', text)\n",
        "        text = re.sub(r'A+\\++', 'excellent', text)\n",
        "\n",
        "        #Lowercase the text\n",
        "        text = text.lower()\n",
        "\n",
        "        # Handle contractions\n",
        "        if self.handle_contractions:\n",
        "            text = self.expand_contractions(text)\n",
        "\n",
        "        # Convert emoticons to text\n",
        "        for emoticon, description in self.emoticon_dict.items():\n",
        "            text = text.replace(emoticon, description)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Convert * to \"star\"\n",
        "        text = text.replace('*', ' star ')\n",
        "\n",
        "\n",
        "        # Retain *, numbers and +\n",
        "        cleaned_text = re.sub(r'[^a-zA-Z0-9\\s\\*\\+]', '', text)\n",
        "        tokens = word_tokenize(cleaned_text)\n",
        "\n",
        "\n",
        "        # Lemmatization and selective stop word removal\n",
        "        # Retain asterisks (*), plus signs (+), 'no', and 'not'\n",
        "        filtered_tokens = [self.lemmatizer.lemmatize(word) for word in tokens if word not in self.stop_words or word in ['*', '+', 'no', 'not',\"don't\"]]\n",
        "\n",
        "        # Check if the resulting list of tokens is empty (all stop words)\n",
        "        if not filtered_tokens:\n",
        "            # Return the cleaned text instead of joining the empty token list\n",
        "            return text\n",
        "        else:\n",
        "            return ' '.join(filtered_tokens)\n",
        "\n",
        "\n",
        "\n",
        "    def convert_numbers(self, text):\n",
        "        # Find all numbers with optional decimal points in the text\n",
        "        numbers = re.findall(r'\\b\\d+(?:\\.\\d+)?', text)\n",
        "\n",
        "        for number in numbers:\n",
        "            word_form = self.inflect_engine.number_to_words(number)\n",
        "            text = text.replace(number, word_form)\n",
        "\n",
        "        return text\n",
        "\n",
        "\n",
        "    def expand_contractions(self, text):\n",
        "        # Define contraction mapping\n",
        "        contractions = {\n",
        "            \"ain't\": \"am not\",\n",
        "            \"aren't\": \"are not\",\n",
        "            \"can't\": \"can not\",\n",
        "            \"'cause\": \"because\",\n",
        "            \"coz\": \"because\",\n",
        "            \"cause\": \"because\",\n",
        "            \"could've\": \"could have\",\n",
        "            \"couldn't\": \"could not\",\n",
        "            \"didn't\": \"did not\",\n",
        "            \"doesn't\": \"does not\",\n",
        "            \"don't\": \"do not\"\n",
        "        }\n",
        "        # Replace contractions with their expansions\n",
        "        for contraction, expansion in contractions.items():\n",
        "            text = text.replace(contraction, expansion)\n",
        "        return text\n",
        "\n",
        "\n",
        "############################################################\n",
        "text_preprocessor = TextPreprocessor(remove_urls=True,handle_contractions=True)\n",
        "\n",
        "# Preprocess the 'Review' column\n",
        "preprocessed_train_reviews = text_preprocessor.transform(train_data['Text'])\n",
        "preprocessed_test_reviews = text_preprocessor.transform(test_data['Text'])\n",
        "\n",
        "\n",
        "# Create a new DataFrame with preprocessed reviews and the original overall ratings\n",
        "processed_train_data = pd.DataFrame({\n",
        "    'Original_Review': train_data['Text'],\n",
        "    'Preprocessed_Review': preprocessed_train_reviews,\n",
        "    'Overall': train_data['Score']\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "processed_test_data= pd.DataFrame({\n",
        "    'id': test_data['Id'],\n",
        "    'Original_Review': test_data['Text'],\n",
        "    'Preprocessed_Review': preprocessed_test_reviews\n",
        "})\n",
        "\n",
        "\n",
        "\n",
        "# Save the combined data to a new CSV file\n",
        "processed_train_data.to_csv(\"processed_train_data_final_smt_pp.csv\", index=False)\n",
        "processed_test_data.to_csv(\"processed_test_data_final_smt_pp.csv\", index=False)\n",
        "\n",
        "processed_test_data.info()\n",
        "processed_train_data.info()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIfJ3r7HOMZM"
      },
      "source": [
        "### Running Count Vectorizer and TFIDF on 6 different classifiers:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYk8IBDiOOoG",
        "outputId": "0ddaabca-2c79-4c79-e165-cdbafcd0923d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-11-e3be3c77048e>:23: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  pre_trim_data_t4['Preprocessed_Review'].fillna('', inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using CountVectorizer with MultinomialNB:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.59      0.57      0.58      5644\n",
            "           2       0.25      0.01      0.03      3214\n",
            "           3       0.34      0.10      0.15      4679\n",
            "           4       0.35      0.26      0.30      8688\n",
            "           5       0.76      0.93      0.84     39602\n",
            "\n",
            "    accuracy                           0.69     61827\n",
            "   macro avg       0.46      0.37      0.38     61827\n",
            "weighted avg       0.63      0.69      0.64     61827\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 3219    71   204   308  1842]\n",
            " [  785    47   352   526  1504]\n",
            " [  525    36   454  1287  2377]\n",
            " [  312    13   186  2218  5959]\n",
            " [  623    22   140  1955 36862]]\n",
            "Using CountVectorizer with LogisticRegression:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.61      0.61      0.61      5644\n",
            "           2       0.30      0.19      0.23      3214\n",
            "           3       0.34      0.24      0.28      4679\n",
            "           4       0.40      0.23      0.29      8688\n",
            "           5       0.80      0.92      0.85     39602\n",
            "\n",
            "    accuracy                           0.71     61827\n",
            "   macro avg       0.49      0.44      0.45     61827\n",
            "weighted avg       0.66      0.71      0.68     61827\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 3429   551   351   155  1158]\n",
            " [  881   599   569   249   916]\n",
            " [  526   459  1134   795  1765]\n",
            " [  231   179   721  1990  5567]\n",
            " [  527   221   521  1741 36592]]\n",
            "Using TfidfVectorizer with MultinomialNB:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.01      0.02      5644\n",
            "           2       0.00      0.00      0.00      3214\n",
            "           3       0.00      0.00      0.00      4679\n",
            "           4       0.40      0.00      0.00      8688\n",
            "           5       0.64      1.00      0.78     39602\n",
            "\n",
            "    accuracy                           0.64     61827\n",
            "   macro avg       0.39      0.20      0.16     61827\n",
            "weighted avg       0.55      0.64      0.50     61827\n",
            "\n",
            "Confusion Matrix:\n",
            " [[   50     0     0     0  5594]\n",
            " [    4     0     0     0  3210]\n",
            " [    0     0     0     0  4679]\n",
            " [    1     0     0     2  8685]\n",
            " [    0     0     0     3 39599]]\n",
            "Using TfidfVectorizer with LogisticRegression:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      0.64      0.64      5644\n",
            "           2       0.35      0.13      0.19      3214\n",
            "           3       0.39      0.23      0.29      4679\n",
            "           4       0.45      0.22      0.29      8688\n",
            "           5       0.79      0.95      0.86     39602\n",
            "\n",
            "    accuracy                           0.72     61827\n",
            "   macro avg       0.52      0.43      0.45     61827\n",
            "weighted avg       0.67      0.72      0.68     61827\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 3615   324   281   119  1305]\n",
            " [  925   426   555   217  1091]\n",
            " [  504   294  1098   845  1938]\n",
            " [  226    80   574  1882  5926]\n",
            " [  466    82   298  1151 37605]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB  # Added import\n",
        "from sklearn.linear_model import LogisticRegression  # Added import\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Load preprocessed data\n",
        "pre_trim_data_t4 = pd.read_csv(r\"processed_train_data_final_t4.csv\")\n",
        "\n",
        "# Fill missing values with empty strings\n",
        "pre_trim_data_t4['Preprocessed_Review'].fillna('', inplace=True)\n",
        "\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = pre_trim_data_t4['Preprocessed_Review']\n",
        "y = pre_trim_data_t4['Overall']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "# Define a function to train, evaluate, and compute confusion matrix\n",
        "def train_evaluate_confusion_matrix(vectorizer, classifier, X_train, X_test, y_train, y_test):\n",
        "    # Vectorize the text\n",
        "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "    X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    y_pred = classifier.predict(X_test_vectorized)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return report, cm\n",
        "\n",
        "# Experiment with different vectorizers and classifiers\n",
        "vectorizers_v3 = [CountVectorizer(), TfidfVectorizer()]\n",
        "classifiers_v3 = [MultinomialNB(), LogisticRegression(max_iter=1000)]\n",
        "\n",
        "for vectorizer in vectorizers_v3:\n",
        "    for classifier in classifiers_v3:\n",
        "        print(f\"Using {vectorizer.__class__.__name__} with {classifier.__class__.__name__}:\")\n",
        "        # Train and evaluate with the review data\n",
        "        report, cm = train_evaluate_confusion_matrix(vectorizer, classifier, X_train, X_test, y_train, y_test)\n",
        "        print(\"Classification Report:\\n\", report)\n",
        "        print(\"Confusion Matrix:\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcARkQDIdHMt"
      },
      "source": [
        "### Table comparison:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "J9RSEIoldK2i",
        "outputId": "7a28149d-9deb-47e5-dbcb-bb490f2ff09c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_13c32 td:hover {\n",
              "  background-color: #ffffb3;\n",
              "}\n",
              "#T_13c32 .index_name {\n",
              "  font-style: italic;\n",
              "  color: darkgrey;\n",
              "  font-weight: normal;\n",
              "}\n",
              "#T_13c32 th:not(.index_name) {\n",
              "  background-color: #000066;\n",
              "  color: white;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_13c32 .col_heading {\n",
              "  font-size: 22px;\n",
              "  text-align: center;\n",
              "  border: none;\n",
              "}\n",
              "#T_13c32 .row_heading {\n",
              "  font-size: 22px;\n",
              "  text-align: center;\n",
              "  border: none;\n",
              "}\n",
              "#T_13c32 .data {\n",
              "  font-size: 22px;\n",
              "  text-align: center;\n",
              "  border: none;\n",
              "}\n",
              "#T_13c32 td.row1.col0 {\n",
              "  background-color: green;\n",
              "  color: white;\n",
              "}\n",
              "#T_13c32 td.row1.col1 {\n",
              "  background-color: green;\n",
              "  color: white;\n",
              "}\n",
              "#T_13c32 caption {\n",
              "  caption-side: top;\n",
              "  font-size: 20px;\n",
              "  color: black;\n",
              "  font-weight: bold;\n",
              "  text-align: center;\n",
              "  margin-bottom: 30px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_13c32\" class=\"dataframe\">\n",
              "  <caption>Comparison of classifiers performance - Accuracy</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_13c32_level0_col0\" class=\"col_heading level0 col0\" >('CountVectorizer',)</th>\n",
              "      <th id=\"T_13c32_level0_col1\" class=\"col_heading level0 col1\" >('TFIDF',)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_13c32_level0_row0\" class=\"row_heading level0 row0\" >MultinomialNB</th>\n",
              "      <td id=\"T_13c32_row0_col0\" class=\"data row0 col0\" >69%</td>\n",
              "      <td id=\"T_13c32_row0_col1\" class=\"data row0 col1\" >64%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_13c32_level0_row1\" class=\"row_heading level0 row1\" >Logistic Regression</th>\n",
              "      <td id=\"T_13c32_row1_col0\" class=\"data row1 col0\" >71%</td>\n",
              "      <td id=\"T_13c32_row1_col1\" class=\"data row1 col1\" >72%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_13c32_level0_row2\" class=\"row_heading level0 row2\" >DecisionTreeClassifier</th>\n",
              "      <td id=\"T_13c32_row2_col0\" class=\"data row2 col0\" >60%</td>\n",
              "      <td id=\"T_13c32_row2_col1\" class=\"data row2 col1\" >59%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_13c32_level0_row3\" class=\"row_heading level0 row3\" >GradientBoostingClassifier</th>\n",
              "      <td id=\"T_13c32_row3_col0\" class=\"data row3 col0\" >68%</td>\n",
              "      <td id=\"T_13c32_row3_col1\" class=\"data row3 col1\" >68%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_13c32_level0_row4\" class=\"row_heading level0 row4\" >AdaBoostClassifier</th>\n",
              "      <td id=\"T_13c32_row4_col0\" class=\"data row4 col0\" >64%</td>\n",
              "      <td id=\"T_13c32_row4_col1\" class=\"data row4 col1\" >64%</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th id=\"T_13c32_level0_row5\" class=\"row_heading level0 row5\" >KNeighborsClassifier</th>\n",
              "      <td id=\"T_13c32_row5_col0\" class=\"data row5 col0\" >63%</td>\n",
              "      <td id=\"T_13c32_row5_col1\" class=\"data row5 col1\" >63%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7c93e37b1a90>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the dataframe for accuracy scores of all 6 classifiers\n",
        "df_accuracy = pd.DataFrame([\n",
        "    ['69%', '64%'],\n",
        "    ['71%', '72%'],\n",
        "    ['60%', '59%'],\n",
        "    ['68%', '68%'],\n",
        "    ['64%', '64%'],\n",
        "    ['63%', '63%']\n",
        "], index=pd.Index(['MultinomialNB', 'Logistic Regression', 'DecisionTreeClassifier', 'GradientBoostingClassifier', 'AdaBoostClassifier', 'KNeighborsClassifier']),\n",
        "   columns=pd.MultiIndex.from_product([['CountVectorizer', 'TFIDF']]))\n",
        "df_accuracy.style\n",
        "\n",
        "\n",
        "s_accuracy = df_accuracy.style\n",
        "# s_f1 = df_f1.style\n",
        "# Add table styles\n",
        "cell_hover = {'selector': 'td:hover', 'props': [('background-color', '#ffffb3')]}\n",
        "index_names = {'selector': '.index_name', 'props': 'font-style: italic; color: darkgrey; font-weight: normal;'}\n",
        "headers = {'selector': 'th:not(.index_name)', 'props': 'background-color: #000066; color: white; text-align: center'}\n",
        "s_accuracy.set_table_styles([cell_hover, index_names, headers])\n",
        "s_accuracy.set_table_styles([\n",
        "        {'selector': '.col_heading', 'props': 'font-size: 22px; text-align: center; border: none;'},\n",
        "    {'selector': '.row_heading', 'props': 'font-size: 22px; text-align: center; border: none;'},\n",
        "    {'selector': '.data', 'props': 'font-size: 22px; text-align: center; border: none;'},\n",
        "    {'selector': 'td.row1.col0',  'props': 'background-color: green; color: white'},\n",
        "    {'selector': 'td.row1.col1',  'props': 'background-color: green; color: white'},\n",
        "], overwrite=False)\n",
        "s_accuracy.set_caption(\"Comparison of classifiers performance - Accuracy\") \\\n",
        "    .set_table_styles([{\n",
        "        'selector': 'caption',\n",
        "        'props': 'caption-side: top; font-size: 20px; color: black; font-weight: bold; text-align: center; margin-bottom: 30px'\n",
        "    }], overwrite=False)\n",
        "\n",
        "# s_accuracy.format('{:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrmKJUgQhuvl"
      },
      "source": [
        "Since <b>Logistic Regression</b> performed the best, we will explore other vectorizer techniques such as <b>count vectorizer with n-grams. TFIDF with n-grams, fastText vectorizer and HashingVectorizer</b> on <b>Logistic Regression</b>."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZs6Wod5xqfS"
      },
      "source": [
        "## HashingVectorizer with Logistic regression:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecdu384txsQi",
        "outputId": "fc431725-35f3-4d8e-c070-87fd2a85a431"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-fe7aa8165f73>:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  train_data['Preprocessed_Review'].fillna('', inplace=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using HashingVectorizer with LogisticRegression:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.63      0.64      0.63      5644\n",
            "           2       0.36      0.11      0.17      3214\n",
            "           3       0.39      0.23      0.29      4679\n",
            "           4       0.45      0.20      0.28      8688\n",
            "           5       0.78      0.95      0.86     39602\n",
            "\n",
            "    accuracy                           0.72     61827\n",
            "   macro avg       0.52      0.43      0.45     61827\n",
            "weighted avg       0.67      0.72      0.68     61827\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 3584   260   267   116  1417]\n",
            " [  882   368   572   193  1199]\n",
            " [  513   246  1090   773  2057]\n",
            " [  226    75   557  1735  6095]\n",
            " [  504    72   280  1007 37739]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Fill missing values with empty strings\n",
        "train_data['Preprocessed_Review'].fillna('', inplace=True)\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = train_data['Preprocessed_Review']\n",
        "y = train_data['Score']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a function to train, evaluate, and compute confusion matrix\n",
        "def train_evaluate_confusion_matrix(vectorizer, classifier, X_train, X_test, y_train, y_test):\n",
        "    # Vectorize the text\n",
        "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "    X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    y_pred = classifier.predict(X_test_vectorized)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return report, cm\n",
        "\n",
        "# Experiment with different vectorizers and classifiers\n",
        "vectorizers_v2 = [HashingVectorizer()]\n",
        "classifiers_v2 = [LogisticRegression(max_iter=1000)]\n",
        "\n",
        "for vectorizer in vectorizers_v2:\n",
        "    for classifier in classifiers_v2:\n",
        "        print(f\"Using {vectorizer.__class__.__name__} with {classifier.__class__.__name__}:\")\n",
        "        # Train and evaluate with the truncated review data\n",
        "        report, cm = train_evaluate_confusion_matrix(vectorizer, classifier, X_train, X_test, y_train, y_test)\n",
        "        print(\"Classification Report:\\n\", report)\n",
        "        print(\"Confusion Matrix:\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q066APUo1HcY"
      },
      "source": [
        "### FastText Vectorizer with Logistic regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tyqFwvI2282K",
        "outputId": "c70c19a3-ff62-41c7-be81-a354b362aea4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, scipy, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.14.1\n",
            "    Uninstalling scipy-1.14.1:\n",
            "      Successfully uninstalled scipy-1.14.1\n",
            "Successfully installed gensim-4.3.3 numpy-1.26.4 scipy-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0pGuWZP43F1S",
        "outputId": "06f91657-ee18-4f36-da2a-746f772546a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-04-04 10:49:04--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 18.173.166.51, 18.173.166.74, 18.173.166.48, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|18.173.166.51|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: wiki-news-300d-1M.vec.zip\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  36.4MB/s    in 9.1s    \n",
            "\n",
            "2025-04-04 10:49:13 (71.6 MB/s) - wiki-news-300d-1M.vec.zip saved [681808098/681808098]\n",
            "\n",
            "Archive:  wiki-news-300d-1M.vec.zip\n",
            "  inflating: wiki-news-300d-1M.vec   \n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
        "!unzip wiki-news-300d-1M.vec.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svPGtAV51NMb",
        "outputId": "28d9ebf3-c0c4-4b2f-cd1e-fdcc19b1267e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using FastTextVectorizer with LogisticRegression:\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.53      0.43      0.47      5644\n",
            "           2       0.33      0.03      0.05      3214\n",
            "           3       0.32      0.09      0.14      4679\n",
            "           4       0.38      0.06      0.10      8688\n",
            "           5       0.70      0.96      0.81     39602\n",
            "\n",
            "    accuracy                           0.67     61827\n",
            "   macro avg       0.45      0.31      0.32     61827\n",
            "weighted avg       0.59      0.67      0.59     61827\n",
            "\n",
            "Confusion Matrix:\n",
            " [[ 2399    64   149    54  2978]\n",
            " [  657    95   260    77  2125]\n",
            " [  468    62   429   286  3434]\n",
            " [  287    27   278   512  7584]\n",
            " [  728    36   215   429 38194]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "\n",
        "class FastTextVectorizer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, ft_model):\n",
        "        self.ft_model = ft_model\n",
        "        self.vector_size = ft_model.vector_size\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([self.transform_text(text) for text in X])\n",
        "\n",
        "    def transform_text(self, text):\n",
        "        words = text.split()\n",
        "        vectors = [self.ft_model[word] for word in words if word in self.ft_model]\n",
        "        if vectors:\n",
        "            return np.mean(vectors, axis=0)\n",
        "        else:\n",
        "            return np.zeros(self.vector_size)\n",
        "\n",
        "\n",
        "# Load the FastText model with a limit\n",
        "ft_model = KeyedVectors.load_word2vec_format(\"wiki-news-300d-1M.vec\")\n",
        "\n",
        "# Fill missing values with empty strings\n",
        "train_data['Preprocessed_Review'].fillna('', inplace=True)\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = train_data['Preprocessed_Review']\n",
        "y = train_data['Score']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a function to train, evaluate, and compute confusion matrix\n",
        "def train_evaluate_confusion_matrix(vectorizer, classifier, X_train, X_test, y_train, y_test):\n",
        "    # Vectorize the text\n",
        "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
        "    X_test_vectorized = vectorizer.transform(X_test)\n",
        "\n",
        "    # Train the classifier\n",
        "    classifier.fit(X_train_vectorized, y_train)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    y_pred = classifier.predict(X_test_vectorized)\n",
        "    report = classification_report(y_test, y_pred)\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    return report, cm\n",
        "\n",
        "# Experiment with FastTextVectorizer and Logistic Regression classifier\n",
        "vectorizer = FastTextVectorizer(ft_model)\n",
        "classifier = LogisticRegression(max_iter=1000)\n",
        "\n",
        "print(f\"Using FastTextVectorizer with {classifier.__class__.__name__}:\")\n",
        "# Train and evaluate with the truncated review data\n",
        "report, cm = train_evaluate_confusion_matrix(vectorizer, classifier, X_train, X_test, y_train, y_test)\n",
        "print(\"Classification Report:\\n\", report)\n",
        "print(\"Confusion Matrix:\\n\", cm)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "id": "hhWi58gE_yLm",
        "outputId": "97adeb2f-6d24-43eb-8d3f-8d96701c7004"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style type=\"text/css\">\n",
              "#T_f3232 td:hover {\n",
              "  background-color: #ffffb3;\n",
              "}\n",
              "#T_f3232 .index_name {\n",
              "  font-style: italic;\n",
              "  color: darkgrey;\n",
              "  font-weight: normal;\n",
              "}\n",
              "#T_f3232 th:not(.index_name) {\n",
              "  background-color: #000066;\n",
              "  color: white;\n",
              "  text-align: center;\n",
              "}\n",
              "#T_f3232 .col_heading {\n",
              "  font-size: 22px;\n",
              "  text-align: center;\n",
              "  border: none;\n",
              "}\n",
              "#T_f3232 .row_heading {\n",
              "  font-size: 22px;\n",
              "  text-align: center;\n",
              "  border: none;\n",
              "}\n",
              "#T_f3232 .data {\n",
              "  font-size: 22px;\n",
              "  text-align: center;\n",
              "  border: none;\n",
              "}\n",
              "#T_f3232 td.row0.col0 {\n",
              "  background-color: green;\n",
              "  color: white;\n",
              "}\n",
              "#T_f3232 caption {\n",
              "  caption-side: top;\n",
              "  font-size: 20px;\n",
              "  color: black;\n",
              "  font-weight: bold;\n",
              "  text-align: center;\n",
              "  margin-bottom: 30px;\n",
              "}\n",
              "</style>\n",
              "<table id=\"T_f3232\" class=\"dataframe\">\n",
              "  <caption>Comparison of HashingVectorizer and FastText Vectorizer using Logistic Regression</caption>\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th class=\"blank level0\" >&nbsp;</th>\n",
              "      <th id=\"T_f3232_level0_col0\" class=\"col_heading level0 col0\" >('HashingVectorizer',)</th>\n",
              "      <th id=\"T_f3232_level0_col1\" class=\"col_heading level0 col1\" >('FastText Vectorizer',)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th id=\"T_f3232_level0_row0\" class=\"row_heading level0 row0\" >Logistic Regression</th>\n",
              "      <td id=\"T_f3232_row0_col0\" class=\"data row0 col0\" >72%</td>\n",
              "      <td id=\"T_f3232_row0_col1\" class=\"data row0 col1\" >67%</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7e44b58d3c90>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the dataframe for accuracy scores of two vectorizers\n",
        "df_accuracy = pd.DataFrame([\n",
        "    ['72%', '67%'],\n",
        "], index=pd.Index(['Logistic Regression']),\n",
        "   columns=pd.MultiIndex.from_product([['HashingVectorizer', 'FastText Vectorizer']]))\n",
        "df_accuracy.style\n",
        "\n",
        "\n",
        "s_accuracy = df_accuracy.style\n",
        "#s_f1 = df_f1.style\n",
        "# Add table styles\n",
        "cell_hover = {'selector': 'td:hover', 'props': [('background-color', '#ffffb3')]}\n",
        "index_names = {'selector': '.index_name', 'props': 'font-style: italic; color: darkgrey; font-weight: normal;'}\n",
        "headers = {'selector': 'th:not(.index_name)', 'props': 'background-color: #000066; color: white; text-align: center'}\n",
        "s_accuracy.set_table_styles([cell_hover, index_names, headers])\n",
        "s_accuracy.set_table_styles([\n",
        "        {'selector': '.col_heading', 'props': 'font-size: 22px; text-align: center; border: none;'},\n",
        "    {'selector': '.row_heading', 'props': 'font-size: 22px; text-align: center; border: none;'},\n",
        "    {'selector': '.data', 'props': 'font-size: 22px; text-align: center; border: none;'},\n",
        "    {'selector': 'td.row0.col0',  'props': 'background-color: green; color: white'},\n",
        "#     {'selector': 'td.row1.col1',  'props': 'background-color: green; color: white'},\n",
        "], overwrite=False)\n",
        "s_accuracy.set_caption(\"Comparison of HashingVectorizer and FastText Vectorizer using Logistic Regression\") \\\n",
        "    .set_table_styles([{\n",
        "        'selector': 'caption',\n",
        "        'props': 'caption-side: top; font-size: 20px; color: black; font-weight: bold; text-align: center; margin-bottom: 30px'\n",
        "    }], overwrite=False)\n",
        "\n",
        "# s_accuracy.format('{:.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGxsgTcsAIwx"
      },
      "source": [
        "# Part - 4: Model training, selection and hyperparameter tuning and evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rErw7BvuALZD",
        "outputId": "383e47d7-5ac6-471c-af2d-21b724394ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: LogisticRegression\n",
            "vectorizer CountVectorizer_Unigram_max_df_0.2\n",
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l1;, score=nan total time=   4.9s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l1;, score=nan total time=   4.3s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l2;, score=0.698 total time=  27.0s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l2;, score=0.699 total time=  28.0s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l1;, score=nan total time=   4.0s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l1;, score=nan total time=   5.9s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l2;, score=0.703 total time=  49.7s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l2;, score=0.703 total time=  55.6s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=1.0, classifier__penalty=l1;, score=nan total time=   5.7s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=1.0, classifier__penalty=l1;, score=nan total time=   5.9s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=1.0, classifier__penalty=l2;, score=0.692 total time= 1.7min\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=1.0, classifier__penalty=l2;, score=0.692 total time= 1.8min\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=10.0, classifier__penalty=l1;, score=nan total time=   3.9s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=10.0, classifier__penalty=l1;, score=nan total time=   7.0s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=10.0, classifier__penalty=l2;, score=0.665 total time= 3.0min\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=10.0, classifier__penalty=l2;, score=0.664 total time= 3.4min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "8 fits failed out of a total of 16.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "8 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.69824588        nan 0.70279494        nan 0.69190551\n",
            "        nan 0.66454243]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: LogisticRegression\n",
            "vectorizer CountVectorizer_Bigram_max_df_0.2\n",
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l1;, score=nan total time=  19.7s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l1;, score=nan total time=  19.0s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l2;, score=0.709 total time= 3.0min\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l2;, score=0.709 total time= 3.1min\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l1;, score=nan total time=  20.4s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l1;, score=nan total time=  20.2s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l2;, score=0.719 total time= 5.7min\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l2;, score=0.719 total time= 5.9min\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=1.0, classifier__penalty=l1;, score=nan total time=  22.6s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=1.0, classifier__penalty=l1;, score=nan total time=  20.4s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=1.0, classifier__penalty=l2;, score=0.713 total time= 6.0min\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=1.0, classifier__penalty=l2;, score=0.714 total time= 7.1min\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=10.0, classifier__penalty=l1;, score=nan total time=  18.7s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=10.0, classifier__penalty=l1;, score=nan total time=  20.2s\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=10.0, classifier__penalty=l2;, score=0.707 total time= 5.3min\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=10.0, classifier__penalty=l2;, score=0.708 total time= 5.4min\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "8 fits failed out of a total of 16.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "8 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\", line 662, in fit\n",
            "    self._final_estimator.fit(Xt, y, **last_step_params[\"fit\"])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 63, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or None penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.70878757        nan 0.71888445        nan 0.71304548\n",
            "        nan 0.70767962]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classifier: LogisticRegression\n",
            "vectorizer CountVectorizer_Trigram_max_df_0.2\n",
            "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l1;, score=nan total time=  51.2s\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l1;, score=nan total time= 1.0min\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l2;, score=0.709 total time= 8.8min\n",
            "[CV 2/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.01, classifier__penalty=l2;, score=0.709 total time= 9.7min\n",
            "[CV 1/2] END classifier=LogisticRegression(max_iter=1000), classifier__C=0.1, classifier__penalty=l1;, score=nan total time=  51.7s\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-45450c5ac0bd>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;31m# Perform grid search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;31m# Save the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1570\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1571\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    968\u001b[0m                     )\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 970\u001b[0;31m                 out = parallel(\n\u001b[0m\u001b[1;32m    971\u001b[0m                     delayed(_fit_and_score)(\n\u001b[1;32m    972\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdelayed_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         )\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable_with_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_sequential_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1917\u001b[0m             \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1920\u001b[0m         \u001b[0;31m# Let's create an ID that uniquely identifies the current call. If the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_batches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1846\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_dispatched_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1847\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1848\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_completed_tasks\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_progress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    864\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 866\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0mrouted_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_method_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouted_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pipeline\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"passthrough\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    586\u001b[0m             )\n\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m             X, fitted_transformer = fit_transform_one_cached(\n\u001b[0m\u001b[1;32m    589\u001b[0m                 \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1549\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0m_print_elapsed_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_clsname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1551\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fit_transform\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m             res = transformer.fit(X, y, **params.get(\"fit\", {})).transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import numpy as np\n",
        "from joblib import dump\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "import os\n",
        "\n",
        "# Create directory for saving models\n",
        "os.makedirs(\"./grid_search_models\", exist_ok=True)\n",
        "\n",
        "\n",
        "# Fill missing values with empty strings\n",
        "train_data['Preprocessed_Review'] = train_data['Preprocessed_Review'].fillna('')\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = train_data['Preprocessed_Review']\n",
        "y = train_data['Score']\n",
        "\n",
        "# Split the data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define a list of classifiers with their associated parameters\n",
        "classifiers = [\n",
        "    {\n",
        "        'classifier': [MultinomialNB()],\n",
        "        'classifier__alpha': [0.1, 0.5, 1.0],  # Smoothing parameter for MultinomialNB\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'classifier': [LogisticRegression(max_iter=1000)],\n",
        "        'classifier__C': [0.01, 0.1, 1.0, 10.0],  # Regularization parameter for LogisticRegression\n",
        "        'classifier__penalty': ['l1', 'l2'],  # Penalty term for LogisticRegression\n",
        "    },\n",
        "    {\n",
        "        'classifier': [GradientBoostingClassifier()],\n",
        "        'classifier__n_estimators': [50, 100, 200],  # The number of boosting stages to perform\n",
        "        'classifier__max_depth': [3, 5, 7],  # Maximum depth of the individual trees\n",
        "    },\n",
        "\n",
        "]\n",
        "max_df_values = [0.2, 0.5, 1.0]\n",
        "vectorizers = []\n",
        "for max_df in max_df_values:\n",
        "    vectorizers.extend([\n",
        "        (CountVectorizer(ngram_range=(1, 1), max_df=max_df), f\"CountVectorizer_Unigram_max_df_{max_df}\"),\n",
        "        (CountVectorizer(ngram_range=(1, 2), max_df=max_df), f\"CountVectorizer_Bigram_max_df_{max_df}\"),\n",
        "        (CountVectorizer(ngram_range=(1, 3), max_df=max_df), f\"CountVectorizer_Trigram_max_df_{max_df}\"),\n",
        "        (TfidfVectorizer(ngram_range=(1, 1), max_df=max_df), f\"TfidfVectorizer_Unigram_max_df_{max_df}\"),\n",
        "        (TfidfVectorizer(ngram_range=(1, 2), max_df=max_df), f\"TfidfVectorizer_Bigram_max_df_{max_df}\"),\n",
        "        (TfidfVectorizer(ngram_range=(1, 3), max_df=max_df), f\"TfidfVectorizer_Trigram_max_df_{max_df}\"),\n",
        "    ])\n",
        "\n",
        "# Create an empty list to store the results\n",
        "results = []\n",
        "\n",
        "# Perform grid search for each combination of classifier and vectorizer\n",
        "for classifier_config in classifiers:\n",
        "    for vectorizer, vectorizer_name in vectorizers:\n",
        "        print(\"Classifier:\", type(classifier_config['classifier'][0]).__name__)\n",
        "        print(\"vectorizer\", vectorizer_name)\n",
        "        # Create a pipeline with the current vectorizer and classifier\n",
        "        pipeline = Pipeline([\n",
        "            ('vectorizer', vectorizer),\n",
        "            ('classifier', classifier_config['classifier']),\n",
        "        ])\n",
        "\n",
        "        # Create GridSearchCV object\n",
        "        grid_search = GridSearchCV(pipeline, classifier_config, cv=2, scoring='accuracy', verbose=3)\n",
        "\n",
        "        # Perform grid search\n",
        "        grid_search.fit(X_train, y_train)\n",
        "\n",
        "        # Save the best model\n",
        "        best_model = grid_search.best_estimator_\n",
        "        model_filename = f\"./grid_search_models/{vectorizer_name}_{type(classifier_config['classifier'][0]).__name__}_best_model.joblib\"\n",
        "        dump(best_model, model_filename)\n",
        "\n",
        "        # Get best parameters and best score\n",
        "        best_params = grid_search.best_params_\n",
        "        best_score = grid_search.best_score_\n",
        "        test_score = grid_search.score(X_test, y_test)\n",
        "\n",
        "        # Store the results\n",
        "        result = {\n",
        "            'vectorizer': vectorizer_name,\n",
        "            'classifier': type(classifier_config['classifier'][0]).__name__,\n",
        "            'best_params': best_params,\n",
        "            'best_score': best_score,\n",
        "            'test_score': test_score,\n",
        "        }\n",
        "        results.append(result)\n",
        "\n",
        "\n",
        "# Print the results\n",
        "for result in results:\n",
        "    print(\"===================================================\")\n",
        "    print(f\"Vectorizer: {result['vectorizer']}, Classifier: {result['classifier']}\")\n",
        "    print(\"Best parameters:\", result['best_params'])\n",
        "    print(\"Best cross-validation score:\", result['best_score'])\n",
        "    print(\"Test set accuracy:\", result['test_score'])\n",
        "    print()\n",
        "\n",
        "    # Print classification report and confusion matrix\n",
        "    print(\"Classification Report:\")\n",
        "    y_pred = result['best_model'].predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(\"===================================================\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
